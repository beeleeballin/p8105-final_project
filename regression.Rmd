---
title: "Regression Analyses"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

# Part 1: State Level Trends, 2001-2015

## Data

We begin by reading in the combined health outcomes data and the combined air pollution and UV radiation data to produce an analysis at the state level. We quickly noticed that some of our variables in the air pollution and UV data were strongly correlated with each other, so we omitted several for the purposes of our regression analysis (collinearity violates our assumptions); the final correlation matrix is given below.

```{r, warning=FALSE, message=FALSE}
library(tidyverse)

outcomes_state <- read_csv("data/lc_mel_asthma_state.csv")
outcomes_county <- read_csv("data/lc_mel_asthma_county.csv")
ap_uv <- read_csv("ap/ap_uv/apuv.csv")

#State-level analysis - fewer predictors
ap_uv_state_slim <- ap_uv %>%
  select(-c(countyfips, county,
            pm25_max_pred, pm25_mean_pred, pm25_pop_pred,
            o3_max_pred, o3_mean_pred, o3_pop_pred,
            i310, i305, i380, edr)) %>%
  group_by(state, year, season) %>%
  #Take medians across county for each season
  summarize(across(pm25_med_pred:edd, median)) %>%
  pivot_wider(names_from = season, values_from = pm25_med_pred:edd)

#State-level analysis - more predictors
ap_uv_state <- ap_uv %>%
  select(-c(countyfips, county)) %>%
  group_by(state, year, season) %>%
  #Take medians across county for each season
  summarize(across(pm25_max_pred:i380, median)) %>%
  pivot_wider(names_from = season, values_from = pm25_max_pred:i380)

outcomes_wider_state <- outcomes_state %>%
  pivot_wider(names_from = outcome, values_from = age_adjusted_incidence_rate)
  
state_analysis <- left_join(outcomes_wider_state, ap_uv_state_slim)

#Check for correlations
state_analysis_corr <- state_analysis %>% 
  select(`lung cancer`:edd_Winter) %>% 
  do(as.data.frame(cor(., method="pearson", use="pairwise.complete.obs"))) %>%
  knitr::kable()
state_analysis_corr
```

## Lung Cancer

### Exploration

Before performing our analysis, we may want to look at some bivariate plots with trends over time to see if there are general trends from 2001 to 2015.

```{r, warning=FALSE, message = FALSE}
library(GGally)

state_analysis %>%
  filter(year %in% 2001:2015) %>%
  ggpairs(columns = c("year","lung cancer", "o3_med_pred_Summer", "pm25_med_pred_Summer"),
          mapping = aes(group = state, color = state),
          columnLabels = c("Year", "Lung Cancer/100,000","Median summer O3, ppm", "PM 2.5, ug/m^3"))

  
state_plot <- state_analysis %>%
  ggplot(aes(x = year, y = `lung cancer`, group = state, color = state)) +
  geom_path()

spring_plot <- state_analysis %>%
  ggplot(aes(x = o3_med_pred_Spring, y = `lung cancer`, group = state, color = state)) +
  geom_point()

summer_plot <- state_analysis %>%
  ggplot(aes(x = o3_med_pred_Summer, y = `lung cancer`, group = state, color = state)) +
  geom_point()

fall_plot <- state_analysis %>%
  ggplot(aes(x = o3_med_pred_Fall, y = `lung cancer`, group = state, color = state)) +
  geom_point()

library(patchwork)
(state_plot + spring_plot) / (summer_plot + fall_plot)
```

### Model Fit - Air quality and lung cancer

We construct a model using the air quality variables (ozone, particulate matter), state, and powers and interactions thereof, then pare down with BIC, limiting our focus to the years 2001-2015.

```{r warning=FALSE, message=FALSE}
state_2001_2015 <- state_analysis %>%
  filter(year %in% 2001:2015) %>%
  #exclude asthma, lots of missingness
  select(-asthma)

aq_lung_df <- state_2001_2015 %>%
  select(-c(melanoma, starts_with("edd")))
#fit_aq <- lm(`lung cancer` ~ .^2, data = aq_lung_df) - this broke in R
fit_aq <- lm(`lung cancer` ~ . +
               year*(o3_med_pred_Spring +
                     o3_med_pred_Summer +
                     o3_med_pred_Fall) +
               year*(pm25_med_pred_Spring +
                     pm25_med_pred_Summer +
                     pm25_med_pred_Fall) +
               state*year, data = aq_lung_df)

step_bic_aq <- step(fit_aq, trace = 0, k = log(nobs(fit_aq)), direction = "backward")
summary(step_bic_aq)
```

Am I reading that right? $R^2$ of 0.97! That sounds too good to be true. Let's look at some diagnostic plots.

```{r warning=FALSE, message=FALSE}
lung_fit <- aq_lung_df %>%
  modelr::add_residuals(step_bic_aq) %>%
  modelr::add_predictions(step_bic_aq)

lung_fit %>%
  ggplot(aes(x = pred, y = resid)) + geom_point() + labs(x = "Predicted value", y = "Residual")
```

These residuals look great! Centered around 0 in a relatively even band. How about normality?

```{r warning=FALSE, message=FALSE}
plot(step_bic_aq, which = 2)
```

That's not ideal. I don't love Box-Cox, but I wonder if it might give us some insight.

```{r warning=FALSE, message=FALSE}
MASS::boxcox(step_bic_aq)
```

Really doesn't help us; the best power of our response variable is about 1. Are there any influential points/high-leverage points?

```{r warning=FALSE, message=FALSE}
plot(step_bic_aq, which = 5)
```

No datapoint with a Cook's distance greater than 0.5, that's good. Are we overfit?

### Cross validation

What happens if we cross-validate against simpler models? We will use leave-one-out and Monte Carlo cross-validation.

```{r warning=FALSE, message=FALSE}
library(modelr)
set.seed(15)
cv_df <- crossv_loo(aq_lung_df)
    
cv_df <- cv_df %>% 
  mutate(
    #Ozone only
    ozone  = map(train, ~lm(`lung cancer` ~ o3_med_pred_Spring + o3_med_pred_Summer +
                              o3_med_pred_Fall, data = .x)),
    #Ozone with year and state
    ozone_state_year  = map(train, ~lm(`lung cancer` ~ o3_med_pred_Spring + o3_med_pred_Summer +
                                         o3_med_pred_Fall + year + state, data = .x)),
    #Ozone with year and state with time interactions
    ozone_state_year2  = map(train, ~lm(`lung cancer` ~ year*(o3_med_pred_Spring +
                                                              o3_med_pred_Summer +
                                                              o3_med_pred_Fall) + year + state +
                                                              year*state, data = .x)),
    
    #BIC model
    bic_fit = map(train, ~step_bic_aq, data = .x)) %>% 
  mutate(
    rmse_ozone = map2_dbl(ozone, test, ~rmse(model = .x, data = .y)),
    rmse_ozone_state_year = map2_dbl(ozone_state_year, test, ~rmse(model = .x, data = .y)),
    rmse_ozone_state_year2 = map2_dbl(ozone_state_year2, test, ~rmse(model = .x, data = .y)),
    rmse_bic_fit = map2_dbl(bic_fit, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + geom_violin() + labs(x = "Model", y = "RMSE")
```

Nice! Our BIC fit does the best on leave-one-out. What about Monte Carlo?

```{r warning=FALSE, message=FALSE}
set.seed(15)
cv_df <- crossv_mc(aq_lung_df, n = 100)
    
cv_df <- cv_df %>% 
  mutate(
    #Ozone only
    ozone  = map(train, ~lm(`lung cancer` ~ o3_med_pred_Spring + o3_med_pred_Summer +
                              o3_med_pred_Fall, data = .x)),
    #Ozone with year and state
    ozone_state_year  = map(train, ~lm(`lung cancer` ~ o3_med_pred_Spring + o3_med_pred_Summer +
                                         o3_med_pred_Fall + year + state, data = .x)),
    #Ozone with year and state with time interactions
    ozone_state_year2  = map(train, ~lm(`lung cancer` ~ year*(o3_med_pred_Spring +
                                                              o3_med_pred_Summer +
                                                              o3_med_pred_Fall) + year + state +
                                                              year*state, data = .x)),
    
    #BIC model
    bic_fit = map(train, ~step_bic_aq, data = .x)) %>% 
  mutate(
    rmse_ozone = map2_dbl(ozone, test, ~rmse(model = .x, data = .y)),
    rmse_ozone_state_year = map2_dbl(ozone_state_year, test, ~rmse(model = .x, data = .y)),
    rmse_ozone_state_year2 = map2_dbl(ozone_state_year2, test, ~rmse(model = .x, data = .y)),
    rmse_bic_fit = map2_dbl(bic_fit, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + geom_violin() + labs(x = "Model", y = "RMSE")
```

Not surprisingly our BIC fit wins again. But there's still something fishy. First, this model has 10 terms and just 45 datapoints - it should almost certainly be overfit, but it still cross-validates well. Second, the $R^2$ for this model is 0.97 - how can that be when it doesn't include smoking, which is probably *the* main determinant of lung cancer? Which variables in this model are the most important?

```{r warning=FALSE, message=FALSE}
broom::tidy(step_bic_aq) %>%
  mutate(
    abs_t = abs(statistic),
    term = as.factor(term),
    term = fct_reorder(term, abs_t)
    ) %>%
  ggplot(aes(x = abs_t, y = term)) +
  geom_col() +
  labs(title = "Relative Importance of Model Terms",
       y = "Model Term", x = "|t| statistic")
```


## Melanoma of the Skin

### Exploration

As before, we create several bivariate plots before constructing our model.

```{r}
state_analysis %>%
  filter(year %in% 2001:2015) %>%
  ggpairs(columns = c("year","melanoma","edd_Spring","edd_Summer"),
          mapping = aes(group = state, color = state),
          columnLabels = c("Year", "Melanoma/100,000", "Spring EDD (J/m^2)", "Summer EDD (J/m^2)"))
```

That's weird. There seem to be negative correlations between EDD and melanoma when we break down by state, but positive correlations overallâ€”an instance of Simpson's paradox.

### Model Fit - Melanoma and UV radiation

How well does UV radiation predict melanoma? Let's find out. This time we limit our analysis to 2005-2015.

```{r message=FALSE, warning=FALSE}
uv_df <- state_2001_2015 %>%
  filter(year >= 2005) %>%
  select(-c(starts_with("pm25"), starts_with("o3"), `lung cancer`))
  
mel_fit <- lm(melanoma ~ .^2, data = uv_df)
step_bic_mel <- step(mel_fit, trace = 0, k = log(nobs(mel_fit)), direction = "backward")
summary(step_bic_mel)
```

This model is huge, it's almost certainly overfit. I'm sure the diagnostics will be terrible.

```{r}
mel_df <- uv_df %>%
  modelr::add_residuals(step_bic_mel) %>%
  modelr::add_predictions(step_bic_mel)

mel_df %>%
  ggplot(aes(x = pred, y = resid)) + geom_point() + labs(x = "Predicted value", y = "Residual")
```

Residuals suggest a bit of heteroscedasticity and curvature but not as bad as I imagined. How about normality?

```{r warning=FALSE, message=FALSE}
plot(step_bic_mel, which = 2)
```

Definitely not normal. High leverage points?

```{r warning=FALSE, message=FALSE}
plot(step_bic_mel, which = 5)
```

Several high leverage points. I think we want a different model. Lets' try a simple one without interactions.

```{r message=FALSE, warning=FALSE}
mel_fit2 <- lm(melanoma ~ ., data = uv_df)
summary(mel_fit2)
```

This comes at a big cost to explanatory power. Notably, the EDD variables aren't significant. How do the residuals look?

```{r message=FALSE, warning=FALSE}
mel_df2 <- uv_df %>%
  modelr::add_residuals(mel_fit2) %>%
  modelr::add_predictions(mel_fit2)

mel_df2 %>%
  ggplot(aes(x = pred, y = resid)) + geom_point() + labs(x = "Predicted value", y = "Residual")
```

We have curvature in the residuals. What is the source?

```{r message=FALSE, warning=FALSE}
summer_resid <- mel_df2 %>%
  ggplot(aes(x = edd_Summer, y = resid)) + geom_point() + labs(x = "Summer Median EDD", y = "Residual")

year_resid <- mel_df2 %>%
  ggplot(aes(x = year, y = resid)) + geom_point() + labs(x = "Year", y = "Residual")

fall_resid <- mel_df2 %>%
  ggplot(aes(x = edd_Fall, y = resid)) + geom_point() + labs(x = "Fall Median EDD", y = "Residual")

state_resid <- mel_df2 %>%
  ggplot(aes(x = state, y = resid)) + geom_violin() + labs(x = "State", y = "Residual")

(summer_resid + year_resid) / (fall_resid + state_resid)
```

Seems like fall EDD and year might be the issues. Try transforming.

```{r}
mel_fit3 <- lm(melanoma ~ state + I(1/year^3) + 
                 edd_Spring + edd_Summer + edd_Fall + edd_Winter,
                 data = uv_df)
summary(mel_fit3)

mel_df3 <- uv_df %>%
  modelr::add_residuals(mel_fit3) %>%
  modelr::add_predictions(mel_fit3)

mel_df3 %>%
  ggplot(aes(x = pred, y = resid)) + geom_point() + labs(x = "Predicted value", y = "Residual")
```

Not much better. How are the other diagnostics?

```{r}
plot(mel_fit2, which = 2)
```

Not very normal...

```{r}
plot(mel_fit2, which = 5)
```

No high-leverage points. Are we overfit? We only have 33 rows.

### Cross validation

```{r message=FALSE, warning=FALSE}
set.seed(15)
cv_df <- crossv_loo(uv_df)
    
cv_df <- cv_df %>% 
  mutate(
    #State and year only
    state_year = map(train, ~lm(melanoma ~ state + year, data = .x)),
    
    #EDD only
    edd = map(train, ~lm(melanoma ~ edd_Winter + edd_Spring + edd_Summer + edd_Fall, data = .x)),
    
    #EDD with year and state, linear
    edd_state_year = map(train, ~mel_fit2, data = .x),
    
    #EDD with year and state with time interactions
    edd_state_year2  = map(train, ~lm(melanoma ~ year*(edd_Winter +
                                                       edd_Spring +
                                                       edd_Summer +
                                                       edd_Fall) + year + state +
                                                       year*state, data = .x)),
    
    #BIC model
    bic_fit = map(train, ~step_bic_mel, data = .x)) %>% 
  mutate(
    rmse_state_year = map2_dbl(state_year, test, ~rmse(model = .x, data = .y)),
    rmse_edd = map2_dbl(edd, test, ~rmse(model = .x, data = .y)),
    rmse_edd_state_year = map2_dbl(edd_state_year, test, ~rmse(model = .x, data = .y)),
    rmse_edd_state_year2 = map2_dbl(edd_state_year2, test, ~rmse(model = .x, data = .y)),
    rmse_bic_fit = map2_dbl(bic_fit, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + geom_violin() + labs(x = "Model", y = "RMSE")
```

The BIC fit wins? How? Will it survive Monte Carlo?

```{r message=FALSE, warning=FALSE}
set.seed(15)
cv_df <- crossv_mc(uv_df, 100)

cv_df <- cv_df %>% 
  mutate(
    #State and year only
    state_year = map(train, ~lm(melanoma ~ state + year, data = .x)),
    
    #EDD only
    edd = map(train, ~lm(melanoma ~ edd_Winter + edd_Spring + edd_Summer + edd_Fall, data = .x)),
    
    #EDD with year and state, linear
    edd_state_year = map(train, ~mel_fit2, data = .x),
    
    #EDD with year and state with time interactions
    edd_state_year2  = map(train, ~lm(melanoma ~ year*(edd_Winter +
                                                       edd_Spring +
                                                       edd_Summer +
                                                       edd_Fall) + year + state +
                                                       year*state, data = .x)),
    
    #BIC model
    bic_fit = map(train, ~step_bic_mel, data = .x)) %>% 
  mutate(
    rmse_state_year = map2_dbl(state_year, test, ~rmse(model = .x, data = .y)),
    rmse_edd = map2_dbl(edd, test, ~rmse(model = .x, data = .y)),
    rmse_edd_state_year = map2_dbl(edd_state_year, test, ~rmse(model = .x, data = .y)),
    rmse_edd_state_year2 = map2_dbl(edd_state_year2, test, ~rmse(model = .x, data = .y)),
    rmse_bic_fit = map2_dbl(bic_fit, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + geom_violin() + labs(x = "Model", y = "RMSE")
```

That model *must* be disgustingly overfit... right?
